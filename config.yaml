title: Tooth Fairy 3 Challenge 2025 
description: Configuration file for the Tooth Fairy 3 Challenge training script.

# --------------------------------------------------
# General Settings
# --------------------------------------------------
general:
  experiment_name: tooth_fairy_3_challenge_2025 
  config_source: yaml #options: cmd, yaml

# --------------------------------------------------
# Experiment & Logging Settings
# --------------------------------------------------
args:
  comet: True
  print_config: False
  tags: null
  is_log_image: True
  is_log_3d: True
  validation_interval: 20
  log_batch_interval: 10
  log_metrics_interval: 10
  log_slice_interval: 10
  log_3d_scene_interval_training: 100
  log_3d_scene_interval_validation: 100
  multiclass_metrics_interval: 100
  multiclass_metrics_epoch: 100

# --------------------------------------------------
# Device & Parallelism
# --------------------------------------------------
  device: cuda
  visible_devices: 0,1
  cuda_device_id: 0
  parallel: False
  gpu_frac: 1.0
  num_threads: 8
  pin_memory: False

# --------------------------------------------------
# Data & Preprocessing
# --------------------------------------------------
  data: data
  cache_dir: data/cache
  clear_cache: False
  use_json_split: True
  use_random_sampler: False
  keys: 
    - image
    - label
  patch_size: 
    - 128
    - 128
    - 128
  spatial_crop_size: 
    - 224
    - 192
    - 160
  spatial_crop_margin:
    - 32
    - 32
    - 32
  crop_foreground: True
  crop_samples: 2
  pixdim: 0.4
  houndsfield_clip: 5000    
  z_score_norm: False  
  rotation_range: 0.1

# --------------------------------------------------
# Model Architecture
# --------------------------------------------------
  n_features: 32
  unet_depth: 5
  norm: instance
  classes: 33

# --------------------------------------------------
# Training Hyperparameters
# --------------------------------------------------
  epochs: 1001
  batch_size: 1
  batch_size_val: 1
  gradient_accumulation: 1
  lr: 1.0e-3
  min_lr: 1.0e-6
  weight_decay: 1.0e-4
  optimizer: AdamW
  adam_eps: 1.0e-8
  adam_ams: False
  grad_clip: True 
  max_grad_norm: 1.0
  use_scaler: False
  autocast_dtype: float32

# --------------------------------------------------
# Scheduler Settings
# --------------------------------------------------
  scheduler_name: cosine_annealing
  warmup_steps: 0
  first_cycle_steps: 1.0    
  scheduler_gamma: 0.5
  min_lr: 1.0e-6

# --------------------------------------------------
# Loss & Metrics
# --------------------------------------------------
  seg_loss_name: DiceCELoss
  classification_loss: cross_entropy #Options: cross_entropy, focal_loss, sice_loss
  correctnes_term: False
  focal_gamma: 0.5
  weighted_cls: True
  include_background_loss: True
  include_background_metrics: False
  include_background_gwd: True
  background_weight: 0.1
  background_penalty: 2.0

# --------------------------------------------------
# Checkpointing & Resume
# --------------------------------------------------
  save_checkpoints: True
  checkpoint_dir: experiments
  save_interval: 100
  save_optimiser_interval: 200
  save_optimizer: True           
  start_epoch: 0
  trained_model: null
  continue_training: False

# --------------------------------------------------
# Early Stopping
# --------------------------------------------------
  stop_early: False
  patience: 4
  delta: 0.001

# --------------------------------------------------
# Determinism & Reproducibility
# --------------------------------------------------
  seed: 48
  deterministic_algorithms: False