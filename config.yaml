title: Tooth Fairy 3 Challenge 2025 
description: Configuration file for the Tooth Fairy 3 Challenge training script.

# --------------------------------------------------
# General Settings
# --------------------------------------------------
general:
  experiment_name: tooth_fairy_3_challenge_2025 
  config_source: yaml #options: cmd, yaml

# --------------------------------------------------
# Experiment & Logging Settings
# --------------------------------------------------
args:
  comet: False
  print_config: False
  tags: null
  is_log_qualitative_2d: True
  is_log_qualitative_3d: False
  validation_interval: 20
  log_batch_interval: 10
  log_metrics_interval: 10
  log_slice_interval: 10
  log_3d_scene_interval_training: 100
  log_3d_scene_interval_validation: 100
  multiclass_metrics_interval: 100
  multiclass_metrics_epoch: 100

# --------------------------------------------------
# Device & Parallelism
# --------------------------------------------------
  device: cuda
  visible_devices: 0,1
  cuda_device_id: 0
  parallel: False
  gpu_frac: 1.0
  num_threads: 8
  pin_memory: False

# --------------------------------------------------
# Data & Preprocessing & Augmentation
# --------------------------------------------------
  data: data
  cache_dir: data/cache
  clear_cache: False
  val_items: 10
  use_json_split: True
  sampler_type: weighted #weighted, random, sequential
  use_thread_loader: True
  use_persistent_dataset: True
  generate_watershed_maps: True
  watershed_maps_dir: data/deep_watershed_maps
  keys: 
    - image
    - label
  patch_size: 
    - 304
    - 304
    - 176
  # spatial_crop_size: 
  #   - 224
  #   - 192
  #   - 160
  # spatial_crop_margin:
  #   - 32
  #   - 32
  #   - 32
  crop_foreground: True
  crop_samples: 2
  pixdim: 0.4
  houndsfield_clip: 3000    
  z_score_norm: False  
  rotation_range: 0.1
  lazy_interpolation: True

# --------------------------------------------------
# Model Architecture
# --------------------------------------------------
  n_features: 32
  unet_depth: 5
  norm: instance
  activation: relu
  backbone_name: resnet34 #Options: resnet18, resnet34, resnet50
  classes: 33

# --------------------------------------------------
# Training Hyperparameters
# --------------------------------------------------
  epochs: 1001
  batch_size: 1
  batch_size_val: 1
  gradient_accumulation: 1
  lr: 1.0e-3
  min_lr: 1.0e-6
  weight_decay: 1.0e-4
  optimizer: AdamW
  adam_eps: 1.0e-8
  adam_ams: False
  grad_clip: True 
  max_grad_norm: 1.0
  use_scaler: False
  autocast_dtype: float32

# --------------------------------------------------
# Scheduler Settings
# --------------------------------------------------
  scheduler_name: warmup_cosine #Options: cosine_annealing, warmup_cosine, warmup_cosine_restarts
  warmup_steps: 10
  first_cycle_steps: 1.0    
  scheduler_gamma: 0.5
  min_lr: 1.0e-6

# --------------------------------------------------
# Loss & Metrics
# --------------------------------------------------
  seg_loss_name: DiceCELoss
  classification_loss: cross_entropy #Options: cross_entropy, focal_loss, sice_loss
  correctnes_term: False
  focal_gamma: 0.5
  weighting_mode: none #Options: none, inverse_frequency_class_weights
  include_background_loss: True
  include_background_metrics: False
  include_background_gwd: True
  background_weight: 0.1
  background_penalty: 2.0

# --------------------------------------------------
# Checkpointing & Resume
# --------------------------------------------------
  save_checkpoints: True
  checkpoint_dir: experiments
  save_interval: 100
  save_optimiser_interval: 200
  save_optimizer: True           
  start_epoch: 0
  trained_model: null
  continue_training: False

# --------------------------------------------------
# Early Stopping
# --------------------------------------------------
  stop_early: False
  patience: 4
  delta: 0.001

# --------------------------------------------------
# Determinism & Reproducibility
# --------------------------------------------------
  seed: 48
  deterministic_algorithms: False